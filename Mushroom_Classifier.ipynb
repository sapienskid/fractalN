{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mushroom Classification with Deep Learning\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/FractalN/blob/main/Mushroom_Classifier.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if we're running in Colab\n",
        "IN_COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Clone repository (includes dataset in data/ folder)\n",
        "    !git clone https://github.com/YOUR_USERNAME/FractalN.git\n",
        "    %cd FractalN\n",
        "    \n",
        "    # Install additional requirements\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Verify dataset is present\n",
        "    !ls -R data/\n",
        "    \n",
        "    # Mount Google Drive for saving results\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Create results directory in Drive\n",
        "    !mkdir -p \"/content/drive/MyDrive/FractalN_Results\"\n",
        "else:\n",
        "    # Verify dataset is present in local environment\n",
        "    if not os.path.exists('data'):\n",
        "        raise FileNotFoundError(\"Dataset not found! Please ensure 'data' directory exists.\")\n",
        "    print(\"Dataset found in local environment.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environment\n",
        "import os\n",
        "import sys\n",
        "from src.gpu_config import setup_gpu\n",
        "import tensorflow as tf\n",
        "\n",
        "# Setup GPU\n",
        "setup_gpu()\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Set results directory based on environment\n",
        "RESULTS_DIR = '/content/drive/MyDrive/FractalN_Results' if IN_COLAB else 'results'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup paths and check for cached processed data\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Define paths\n",
        "    DRIVE_ROOT = '/content/drive/MyDrive/FractalN_Data'\n",
        "    AUGMENTED_DATA_PATH = f\"{DRIVE_ROOT}/final_processed_data.zip\"  # Final processed data after all steps\n",
        "    RESULTS_DIR = f\"{DRIVE_ROOT}/Results\"\n",
        "    \n",
        "    # Create directories\n",
        "    !mkdir -p \"{DRIVE_ROOT}\"\n",
        "    !mkdir -p \"{RESULTS_DIR}\"\n",
        "    \n",
        "    # Check if final processed data exists in Drive\n",
        "    NEED_PROCESSING = not os.path.exists(AUGMENTED_DATA_PATH)\n",
        "else:\n",
        "    RESULTS_DIR = 'results'\n",
        "    NEED_PROCESSING = not os.path.exists('data/processed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Complete Data Pipeline\n",
        "Process data in three steps:\n",
        "1. Organize raw data\n",
        "2. Augment organized data\n",
        "3. Preprocess augmented data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if NEED_PROCESSING:\n",
        "    print(\"No cached processed data found. Starting complete data pipeline...\")\n",
        "    \n",
        "    # Step 1: Organize raw data\n",
        "    print(\"\\n1. Organizing raw data...\")\n",
        "    from src.utils.reorganize_data import reorganize_mushroom_data\n",
        "    reorganize_mushroom_data()\n",
        "    \n",
        "    # Step 2: Augment organized data\n",
        "    print(\"\\n2. Augmenting organized data...\")\n",
        "    from src.utils.augment_mushroom_data import augment_mushroom_data\n",
        "    augment_mushroom_data(target_count=20000)\n",
        "    \n",
        "    # Step 3: Preprocess augmented data\n",
        "    print(\"\\n3. Preprocessing augmented data...\")\n",
        "    from src.utils.preprocess_data import preprocess_dataset\n",
        "    preprocess_dataset(\n",
        "        data_dir='data/mushroom_data',\n",
        "        output_dir='data/processed',\n",
        "        test_size=0.2,\n",
        "        img_size=(224, 224)\n",
        "    )\n",
        "    \n",
        "    # Cache the final processed data\n",
        "    if IN_COLAB:\n",
        "        print(\"\\nSaving final processed data to Google Drive...\")\n",
        "        !zip -r \"{AUGMENTED_DATA_PATH}\" data/processed\n",
        "        print(f\"Final processed data saved to: {AUGMENTED_DATA_PATH}\")\n",
        "else:\n",
        "    print(\"Found cached processed data. Loading...\")\n",
        "    if IN_COLAB:\n",
        "        !unzip -q \"{AUGMENTED_DATA_PATH}\" -d \"data/\"\n",
        "    print(\"Cached data loaded successfully!\")\n",
        "\n",
        "# Verify final data structure and distribution\n",
        "!tree data/processed -L 3\n",
        "\n",
        "print(\"\\nFinal dataset distribution:\")\n",
        "for split in ['train', 'test']:\n",
        "    print(f\"\\n{split.capitalize()} set:\")\n",
        "    for category in ['poisonous', 'edible']:\n",
        "        count = len(list(Path(f'data/processed/{split}/{category}').glob('*.jpg')))\n",
        "        print(f\"{category}: {count} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training\n",
        "Train using the fully processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.train import train_model\n",
        "from src.model import create_model\n",
        "!rm -rf data/processed/*\n",
        "print(\"Starting model training...\")\n",
        "train_model(preprocess=True)  # Set to True for first run\n",
        "\n",
        "print(\"\\nDisplaying training results...\")\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "img = mpimg.imread('training_history.png')\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTraining Metrics:\")\n",
        "with open('training_metrics.txt', 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Evaluation and Prediction\n",
        "Test the trained model on sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.predict import predict_mushroom\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "def test_random_images(num_samples=3):\n",
        "    test_dir = Path('data/processed/test')\n",
        "    \n",
        "    for category in ['edible', 'poisonous']:\n",
        "        print(f\"\\nTesting {category} mushrooms:\")\n",
        "        category_path = test_dir / category\n",
        "        image_files = list(category_path.glob('*.[Jj][Pp][Gg]'))\n",
        "        \n",
        "        for _ in range(num_samples):\n",
        "            test_image = random.choice(image_files)\n",
        "            print(f\"\\nImage: {test_image.name}\")\n",
        "            prediction, confidence = predict_mushroom(\n",
        "                'mushroom_classifier.keras',\n",
        "                str(test_image)\n",
        "            )\n",
        "            print(f\"Predicted: {prediction}\")\n",
        "            print(f\"Confidence: {confidence:.2%}\")\n",
        "\n",
        "# Test model on random images\n",
        "test_random_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Model and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to Google Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    !cp mushroom_classifier.keras \"{RESULTS_DIR}/\"\n",
        "    !cp best_model.keras \"{RESULTS_DIR}/\"\n",
        "    !cp training_history.png \"{RESULTS_DIR}/\"\n",
        "    !cp training_metrics.txt \"{RESULTS_DIR}/\"\n",
        "    !cp training_log.csv \"{RESULTS_DIR}/\"\n",
        "    print(f\"Model and results saved to Google Drive: {RESULTS_DIR}\")\n",
        "else:\n",
        "    !mkdir -p results\n",
        "    !cp mushroom_classifier.keras results/\n",
        "    !cp best_model.keras results/\n",
        "    !cp training_history.png results/\n",
        "    !cp training_metrics.txt results/\n",
        "    !cp training_log.csv results/\n",
        "    print(\"Model and results saved in 'results' directory\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mushroom_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
