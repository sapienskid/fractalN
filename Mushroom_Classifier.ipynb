{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mushroom Classification with Deep Learning\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/FractalN/blob/main/Mushroom_Classifier.ipynb)\n",
        "\n",
        "This notebook trains a mushroom classifier using transfer learning and data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if we're running in Colab\n",
        "IN_COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Clone repository (includes dataset in data/ folder)\n",
        "    !git clone https://github.com/YOUR_USERNAME/FractalN.git\n",
        "    %cd FractalN\n",
        "    \n",
        "    # Install additional requirements\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Verify dataset is present\n",
        "    !ls -R data/\n",
        "    \n",
        "    # Mount Google Drive for saving results\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Create results directory in Drive\n",
        "    !mkdir -p \"/content/drive/MyDrive/FractalN_Results\"\n",
        "else:\n",
        "    # Verify dataset is present in local environment\n",
        "    if not os.path.exists('data'):\n",
        "        raise FileNotFoundError(\"Dataset not found! Please ensure 'data' directory exists.\")\n",
        "    print(\"Dataset found in local environment.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environment\n",
        "import os\n",
        "import sys\n",
        "from src.gpu_config import setup_gpu\n",
        "import tensorflow as tf\n",
        "\n",
        "# Setup GPU\n",
        "setup_gpu()\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Set results directory based on environment\n",
        "RESULTS_DIR = '/content/drive/MyDrive/FractalN_Results' if IN_COLAB else 'results'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Organization\n",
        "First, we'll organize raw images into proper categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.reorganize_data import reorganize_mushroom_data\n",
        "\n",
        "# Organize raw data\n",
        "reorganize_mushroom_data()\n",
        "\n",
        "# Verify directory structure\n",
        "!tree data/mushroom_data -L 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Augmentation\n",
        "Augment the dataset to improve model generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.augment_mushroom_data import augment_mushroom_data\n",
        "\n",
        "# Augment data to reach target count per class\n",
        "augment_mushroom_data(target_count=20000)\n",
        "\n",
        "# Show class distribution after augmentation\n",
        "!find data/mushroom_data/poisonous -type f | wc -l\n",
        "!find data/mushroom_data/edible -type f | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing\n",
        "Preprocess and split the dataset into train/test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.preprocess_data import preprocess_dataset\n",
        "\n",
        "# Preprocess and split dataset\n",
        "preprocess_dataset(\n",
        "    data_dir='data/mushroom_data',\n",
        "    output_dir='data/processed',\n",
        "    test_size=0.2,\n",
        "    img_size=(224, 224)\n",
        ")\n",
        "\n",
        "# Verify processed data structure\n",
        "!tree data/processed -L 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Training\n",
        "Train the CNN model on the processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.train import train_model\n",
        "\n",
        "# Train the model\n",
        "train_model()\n",
        "\n",
        "# Display training history\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "img = mpimg.imread('training_history.png')\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Show training metrics\n",
        "print(\"\\nTraining Metrics:\")\n",
        "!cat training_metrics.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation and Prediction\n",
        "Test the trained model on sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.predict import predict_mushroom\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "def test_random_images(num_samples=3):\n",
        "    test_dir = Path('data/processed/test')\n",
        "    \n",
        "    for category in ['edible', 'poisonous']:\n",
        "        print(f\"\\nTesting {category} mushrooms:\")\n",
        "        category_path = test_dir / category\n",
        "        image_files = list(category_path.glob('*.[Jj][Pp][Gg]'))\n",
        "        \n",
        "        for _ in range(num_samples):\n",
        "            test_image = random.choice(image_files)\n",
        "            print(f\"\\nImage: {test_image.name}\")\n",
        "            prediction, confidence = predict_mushroom(\n",
        "                'mushroom_classifier.keras',\n",
        "                str(test_image)\n",
        "            )\n",
        "            print(f\"Predicted: {prediction}\")\n",
        "            print(f\"Confidence: {confidence:.2%}\")\n",
        "\n",
        "# Test model on random images\n",
        "test_random_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Model and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to Google Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    !cp mushroom_classifier.keras \"{RESULTS_DIR}/\"\n",
        "    !cp best_model.keras \"{RESULTS_DIR}/\"\n",
        "    !cp training_history.png \"{RESULTS_DIR}/\"\n",
        "    !cp training_metrics.txt \"{RESULTS_DIR}/\"\n",
        "    !cp training_log.csv \"{RESULTS_DIR}/\"\n",
        "    print(f\"Model and results saved to Google Drive: {RESULTS_DIR}\")\n",
        "else:\n",
        "    !mkdir -p results\n",
        "    !cp mushroom_classifier.keras results/\n",
        "    !cp best_model.keras results/\n",
        "    !cp training_history.png results/\n",
        "    !cp training_metrics.txt results/\n",
        "    !cp training_log.csv results/\n",
        "    print(\"Model and results saved in 'results' directory\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mushroom_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
