{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# FractalN Mushroom Classification\n",
        "\n",
        "This notebook runs the training process in Google Colab using the main.py script.\n",
        "\n",
        "## Setup\n",
        "First, let's clone the repository and install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "environment_setup"
      },
      "outputs": [],
      "source": [
        "# Check CUDA and setup environment\n",
        "!nvidia-smi\n",
        "\n",
        "# Setup repository and dependencies\n",
        "import os\n",
        "if not os.path.exists('FractalN'):\n",
        "    !git clone https://github.com/YOUR_USERNAME/FractalN.git\n",
        "%cd FractalN\n",
        "\n",
        "# Install dependencies with error handling\n",
        "try:\n",
        "    !pip install -r requirements.txt\n",
        "    import subprocess\n",
        "    cuda_output = subprocess.getoutput('nvcc --version')\n",
        "    if 'release 11' in cuda_output:\n",
        "        !pip install cupy-cuda11x\n",
        "    elif 'release 12' in cuda_output:\n",
        "        !pip install cupy-cuda12x\n",
        "    else:\n",
        "        !pip install cupy-cuda110\n",
        "except Exception as e:\n",
        "    print(f\"Error in setup: {e}\")\n",
        "    !pip install numpy pandas torch torchvision cupy-cuda11x\n",
        "\n",
        "# Setup Python path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, str(Path.cwd().resolve()))\n",
        "sys.path.insert(0, str(Path.cwd().resolve() / 'src'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_gpu_section"
      },
      "source": [
        "## GPU Check\n",
        "Let's verify GPU availability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_test"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def verify_gpu():\n",
        "    print(\"GPU Verification:\")\n",
        "    try:\n",
        "        # Basic GPU check\n",
        "        device = cp.cuda.Device(0)\n",
        "        print(f\"GPU Device: {device.attributes['DEVICE_NAME'].decode('utf-8')}\")\n",
        "        print(f\"Memory: {device.mem_info[1]/1024**3:.2f} GB Total\")\n",
        "        \n",
        "        # Quick performance test\n",
        "        size = 1000000\n",
        "        start = time.time()\n",
        "        x = cp.random.random(size)\n",
        "        y = cp.random.random(size)\n",
        "        z = x + y\n",
        "        cp.cuda.Device().synchronize()\n",
        "        print(f\"Performance test completed in {time.time() - start:.3f}s\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"GPU verification failed: {e}\")\n",
        "        return False\n",
        "\n",
        "verify_gpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## Training\n",
        "Now we'll run the training using main.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training"
      },
      "outputs": [],
      "source": [
        "# Run training using properly imported modules\n",
        "from src.gpu_utils import configure_gpu\n",
        "from src.main import train\n",
        "\n",
        "# Configure GPU with memory pool\n",
        "configure_gpu()\n",
        "\n",
        "# Run training\n",
        "train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monitor_gpu_section"
      },
      "source": [
        "## Monitor GPU Usage\n",
        "Add this cell to your notebook to monitor GPU usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "monitor_gpu"
      },
      "outputs": [],
      "source": [
        "# Add monitoring cell\n",
        "def monitor_gpu():\n",
        "    if cp.cuda.is_available():\n",
        "        device = cp.cuda.Device(0)\n",
        "        mem_info = device.mem_info\n",
        "        used_gb = (mem_info[1] - mem_info[0]) / 1024**3\n",
        "        total_gb = mem_info[1] / 1024**3\n",
        "        print(f\"GPU Memory: {used_gb:.1f}GB / {total_gb:.1f}GB ({used_gb/total_gb*100:.1f}%)\")\n",
        "\n",
        "# Monitor GPU usage every 5 minutes during training\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "def training_with_monitoring():\n",
        "    start_time = time.time()\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        monitor_gpu()\n",
        "        time.sleep(300)  # Update every 5 minutes\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "FractalN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
