{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# FractalN Mushroom Classification\n",
        "\n",
        "This notebook runs the training process in Google Colab using the main.py script.\n",
        "\n",
        "## Setup\n",
        "First, let's clone the repository and install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "environment_setup"
      },
      "outputs": [],
      "source": [
        "# First check CUDA version\n",
        "!nvidia-smi\n",
        "!nvcc --version\n",
        "\n",
        "# Install the correct CuPy version based on CUDA version\n",
        "import subprocess\n",
        "cuda_output = subprocess.getoutput('nvcc --version')\n",
        "if 'release 11' in cuda_output:\n",
        "    !pip install cupy-cuda11x\n",
        "elif 'release 12' in cuda_output:\n",
        "    !pip install cupy-cuda12x\n",
        "else:\n",
        "    !pip install cupy-cuda110  # Fallback for older versions\n",
        "\n",
        "# Install other requirements\n",
        "!pip install colorama tqdm pillow numpy opencv-python\n",
        "\n",
        "# Clone repository\n",
        "!git clone https://github.com/YOUR_USERNAME/FractalN.git\n",
        "%cd FractalN\n",
        "\n",
        "# Verify imports\n",
        "import cupy as cp\n",
        "print(f\"\\nCuPy version: {cp.__version__}\")\n",
        "print(f\"CUDA available: {cp.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_gpu_section"
      },
      "source": [
        "## GPU Check\n",
        "Let's verify GPU availability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify_gpu"
      },
      "outputs": [],
      "source": [
        "# Verify CuPy can access GPU\n",
        "import cupy as cp\n",
        "\n",
        "# Test GPU computation\n",
        "x = cp.array([1, 2, 3])\n",
        "print(f\"CuPy GPU available: {cp.cuda.is_available()}\")\n",
        "if cp.cuda.is_available():\n",
        "    device = cp.cuda.Device(0)\n",
        "    print(f\"GPU Device: {device.attributes['DEVICE_NAME'].decode('utf-8')}\")\n",
        "    print(f\"Total Memory: {device.mem_info[1]/1024**3:.2f} GB\")\n",
        "\n",
        "# Test basic computation\n",
        "y = cp.square(x)\n",
        "print(f\"\\nTest computation on GPU: {x} squared = {y}\")\n",
        "print(\"GPU test successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## Training\n",
        "Now we'll run the training using main.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from gpu_utils import configure_gpu\n",
        "from main import train\n",
        "\n",
        "# Configure GPU with memory pool\n",
        "configure_gpu()\n",
        "\n",
        "# Run your custom CNN implementation\n",
        "train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "FractalN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
