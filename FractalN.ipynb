{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# FractalN Mushroom Classification\n",
        "\n",
        "This notebook runs the training process in Google Colab using the main.py script.\n",
        "\n",
        "## Setup\n",
        "First, let's clone the repository and install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "environment_setup"
      },
      "outputs": [],
      "source": [
        "# First check CUDA version\n",
        "!nvidia-smi\n",
        "!nvcc --version\n",
        "\n",
        "# Clone repository\n",
        "!git clone https://github.com/sapienskid/FractalN.git\n",
        "%cd FractalN\n",
        "\n",
        "# Add src directory to Python path\n",
        "import sys\n",
        "sys.path.append('./src')\n",
        "\n",
        "\n",
        "\n",
        "# Install correct CuPy version based on CUDA\n",
        "import subprocess\n",
        "cuda_output = subprocess.getoutput('nvcc --version')\n",
        "if 'release 11' in cuda_output:\n",
        "    !pip install cupy-cuda11x\n",
        "elif 'release 12' in cuda_output:\n",
        "    !pip install cupy-cuda12x\n",
        "else:\n",
        "    !pip install cupy-cuda110\n",
        "\n",
        "# Install base requirements first\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Verify setup\n",
        "import cupy as cp\n",
        "print(f\"\\nSetup verification:\")\n",
        "print(f\"CuPy version: {cp.__version__}\")\n",
        "print(f\"CUDA available: {cp.cuda.is_available()}\")\n",
        "print(\"\\nRepository contents:\")\n",
        "!ls\n",
        "print(\"\\nDataset contents:\")\n",
        "!ls data/processed_mushroom_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_gpu_section"
      },
      "source": [
        "## GPU Check\n",
        "Let's verify GPU availability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify_gpu"
      },
      "outputs": [],
      "source": [
        "# Verify CuPy can access GPU\n",
        "import cupy as cp\n",
        "\n",
        "# Test GPU computation\n",
        "x = cp.array([1, 2, 3])\n",
        "print(f\"CuPy GPU available: {cp.cuda.is_available()}\")\n",
        "if cp.cuda.is_available():\n",
        "    device = cp.cuda.Device(0)\n",
        "    print(f\"GPU Device: {device.attributes['DEVICE_NAME'].decode('utf-8')}\")\n",
        "    print(f\"Total Memory: {device.mem_info[1]/1024**3:.2f} GB\")\n",
        "\n",
        "# Test basic computation\n",
        "y = cp.square(x)\n",
        "print(f\"\\nTest computation on GPU: {x} squared = {y}\")\n",
        "print(\"GPU test successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpu_test_section"
      },
      "source": [
        "## GPU Performance Test\n",
        "Let's run a computation test to verify GPU acceleration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_test"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def test_gpu_computation():\n",
        "    # Create large arrays for testing\n",
        "    size = 10000000\n",
        "    \n",
        "    # CPU computation using NumPy\n",
        "    print(\"Starting CPU computation...\")\n",
        "    start_cpu = time.time()\n",
        "    x_cpu = np.random.random(size)\n",
        "    y_cpu = np.random.random(size)\n",
        "    z_cpu = x_cpu + y_cpu\n",
        "    cpu_time = time.time() - start_cpu\n",
        "    \n",
        "    # GPU computation using CuPy\n",
        "    print(\"\\nStarting GPU computation...\")\n",
        "    start_gpu = time.time()\n",
        "    x_gpu = cp.random.random(size)\n",
        "    y_gpu = cp.random.random(size)\n",
        "    z_gpu = x_gpu + y_gpu\n",
        "    cp.cuda.Device().synchronize()  # Wait for GPU to finish\n",
        "    gpu_time = time.time() - start_gpu\n",
        "    \n",
        "    # Print results with color formatting\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"GPU Performance Test Results:\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"CPU time: {cpu_time:.4f} seconds\")\n",
        "    print(f\"GPU time: {gpu_time:.4f} seconds\")\n",
        "    print(f\"GPU speedup: {cpu_time/gpu_time:.2f}x\")\n",
        "    \n",
        "    # Print GPU information\n",
        "    print(\"\\nGPU Information:\")\n",
        "    print(\"-\"*30)\n",
        "    print(f\"Current Device: {cp.cuda.Device().id}\")\n",
        "    print(f\"Device Name: {cp.cuda.runtime.getDeviceProperties(cp.cuda.Device().id)['name'].decode()}\")\n",
        "    print(f\"Memory Usage: {cp.cuda.runtime.memGetInfo()[0]/1024**3:.2f} GB free of {cp.cuda.runtime.memGetInfo()[1]/1024**3:.2f} GB total\")\n",
        "\n",
        "# Run the test\n",
        "try:\n",
        "    test_gpu_computation()\n",
        "except Exception as e:\n",
        "    print(f\"\\nError: {str(e)}\")\n",
        "    print(\"\\nTroubleshooting tips:\")\n",
        "    print(\"1. Make sure you're using a GPU runtime in Colab (Runtime > Change runtime type > GPU)\")\n",
        "    print(\"2. Verify CuPy installation was successful\")\n",
        "    print(\"3. Check if CUDA version matches your GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## Training\n",
        "Now we'll run the training using main.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training"
      },
      "outputs": [],
      "source": [
        "# Run training using properly imported modules\n",
        "from src.gpu_utils import configure_gpu\n",
        "from src.main import train\n",
        "\n",
        "# Configure GPU with memory pool\n",
        "configure_gpu()\n",
        "\n",
        "# Run training\n",
        "train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "FractalN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
